<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&amp;display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha512-Evv84Mr4kqVGRNSgIGL/F/aIDqQb7xQ2vcrdIwxfjThSH8CSR7PBEakCr51Ck+w+/U6swU2Im1vVX0SVk9ABhg==" crossorigin="anonymous" referrerpolicy="no-referrer">
    

    <link rel="stylesheet" href="css/style.css">
    <link rel="stylesheet" href="css/syntax.css">

    <script src="/assets/js/script.js"></script>
    <!-- Google Tag Manager -->
    <!-- Google tag (gtag.js) -->
    <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-NK6SXX49WX"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'G-NK6SXX49WX');
    </script>
        <!-- End Google Tag Manager -->
    
    <title>Hao-Yu Chan's Portfolio</title>
    

</head>
<body>
    <!-- NAVBAR -->
     <!-- _includes/nav.html -->
<nav>
    <div class="left">
        <a href="./index.html">Hao-Yu Chan</a>
    </div>

    <!-- Desktop Menu -->
    <div class="right desktop-nav">
        <a href="./index.html">
            <span>Home</span>
        </a>
        <a href="#projects">
            <span>Projects</span>
        </a>
        <a href="https://drive.google.com/file/d/11pgtXnIpYX-4J0UnDVH8iClthl-vGAJc/view?usp=sharing" target="_blank" rel="noopener noreferrer">
            <span>Resume</span>
        </a>
    </div>

    <!-- Mobile Menu Button -->
    <button class="menu-toggle" aria-label="Toggle menu">
        <i class="fa fa-bars fa-2x"></i>
    </button>

    <!-- Mobile Menu -->
    <div class="mobile-nav">
        <a href="./index.html">
            <span>Home</span>
        </a>
        <a href="#projects">
            <span>Projects</span>
        </a>
        <a href="https://drive.google.com/file/d/11pgtXnIpYX-4J0UnDVH8iClthl-vGAJc/view?usp=sharing" target="_blank" rel="noopener noreferrer">
            <span>Resume</span>
        </a>
    </div>
</nav>

     <div class="page">
<!-- SECTION 1: Hero -->
<section class="hero-section">
    <div class="group">
        <div class="text">
            <h2>
                I'm Hao-Yu Chan 
                
                <span class="external-links">
                            <a href="https://www.linkedin.com/in/haoyuchan/" target="_blank">
                                <i class="fa-brands fa-linkedin"></i>
                            </a>
                            <a href="https://github.com/ChanHaoHao" target="_blank">
                                <i class="fa-brands fa-github"></i>
                            </a>
                            <a href="mailto: hychan@umich.edu" target="_blank">
                                <i class="fa-solid fa-envelope"></i>
                            </a>
                </span>
                
            </h2>
            
            <h3> Actively seeking for full-time robotics software positions </h3>
            <p> Graduate student in Electrical and Computer Engineering at the University of Michigan with a focus in Robotics. Experienced in building integrated robotic systems through hands-on projects involving autonomous navigation, computer vision, and system control. Strong background in applying real-time perception and planning techniques to solve complex challenges in dynamic environments. Passionate about developing intelligent robotic solutions that bridge hardware and software for practical, real-world applications.</p>
            <div class="links">
                <a href="#projects">
                    <i class="fa-solid fa-pen"></i>
                    <span>Projects</span>
                </a>
                <a href="#skills">
                    <i class="fa-solid fa-hammer"></i>
                    <span>Skills</span>
                </a>
                <!-- <a href="mailto:hychan@umich.edu">
                    <i class="fa-solid fa-envelope"></i>
                    <span>Contact Me</span>
                </a> -->
            </div>
        </div>

        <div class="headshot">
            <img src="./assets/images/profile-image/Hychan.jpg" alt="john doe headshot">       
        </div>
    </div>
    
</section>

<div class="arrow"> 
    <a href="#work">
        More About Me
    <i class="fa-solid fa-angles-down"></i>
    </a> 
</div>

<!-- SECTION : work experience-->
<section id="work" class="work-section">
  <h2>Experience</h2>

  <div class="work-grid-section">
    <div class="work-container">
      <div class="work-text">
        <h2>Hybrid Dynamic Robotics Lab</h2>
        <p class="work-dates"><em>January 2025 - Present</em></p>
        <p class="work-position">Graduate Research Assistant</p>
      </div>
      <div class="work-skills">
              <span class="skill">Python</span>
              <span class="skill">PyTorch</span>
              <span class="skill">Open3D</span>
              <span class="skill">Gaussian splat</span>
              <span class="skill">3D reconstruction</span>
              <span class="skill">Semantic</span>
              <span class="skill">VGGT</span>
              <span class="skill">G-ICP</span>
              <span class="skill">DINO</span>
      </div>
      <div class="work-content">
        <ul class="contents">
          <li>Developed a 3D reconstruction pipeline combining VGGT and GICP for long-term video sequences, achieving an average of 11× lower reconstruction error compared to Monocular Gaussian Splatting SLAM.</li>
          <li>Achieved 0.9 mIoU with DINO features and implemented a semantic head in PyTorch using only RGB input on Scannetpp dataset</li>
        </ul>
      </div>
    </div>

    <div class="work-container">
      <div class="work-text">
        <h2>FII, USA</h2>
        <p class="work-dates"><em>May 2025 - Present</em></p>
        <p class="work-position">Automation Intern</p>
      </div>
      <div class="work-skills">
              <span class="skill">Measurement System Analysis</span>
              <span class="skill">Python</span>
              <span class="skill">C#</span>
              <span class="skill">HALCON</span>
              <span class="skill">Computer Vision</span>
              <span class="skill">SolidWorks</span>
              <span class="skill">Fast Prototyping</span>
              <span class="skill">Automation Machine</span>
      </div>
      <div class="work-content">
        <ul class="contents">
          <li>Performed Gauge R&R analysis on the factory vision system to evaluate measurement reliability and repeatability.</li>
          <li>Developed a custom vision pipeline in HALCON to detect pedestal contours and identify scratches on both dulled and shiny surfaces. Achieved 99% recognition accuracy for pedestal detection, with robust scratch identification across varying surface finishes.</li>
          <li>Improved the placement algorithm for Phase Change Material (PCM) application, achieving sub-0.5 mm accuracy when aligning a 26.1×26.8 mm PCM onto a 27×28 mm pedestal. This improvement increased yield rate from 52.5% to 97.4%, significantly boosting production reliability and consistency.</li>
          <li>Designed a new automation machine for DIMM module assembly focused on maximizing throughput. By implementing an innovative mechanical design, the system increased units per hour (UPH) from 43 to 57.</li>
          <li>Developed an ergonomic automation machine for assembling HDD storage servers, with a focus on operator safety and ease of use. The design reduces physical strain during manual interactions while ensuring consistent, high-quality assembly in a high-throughput environment.</li>
        </ul>
      </div>
    </div>

    <div class="work-container">
      <div class="work-text">
        <h2>Center for Artificial Intelligence and Advanced Robotics</h2>
        <p class="work-dates"><em>June 2023 - April 2024</em></p>
        <p class="work-position">Research Assistant</p>
      </div>
      <div class="work-skills">
              <span class="skill">Human Robot Interaction</span>
              <span class="skill">Python</span>
              <span class="skill">Android</span>
              <span class="skill">Java</span>
              <span class="skill">Full-stack</span>
              <span class="skill">SQLite</span>
      </div>
      <div class="work-content">
        <h3><strong>Topic: Companion Healthcare Aid Robot Manager for Caring the Elders (CHARM)</strong></h3>
        <ul class="contents">
          <li>Tested and validated new robot behaviors through Android-based HRI applications, collecting 100+ user feedback entries and improving system usability scale (SUS) to a score of 79.6.</li>
          <li>Created an interactive introduction script to familiarize users with the robot, and enhance user engagement.</li>
          <li>Implemented face recognition login and enabled the robot to initiate friendly small talk when a user is detected.</li>
          <li>Designed APIs to support development of Android and Web applications, patient management systems.</li>
        </ul>
      </div>
    </div>

    <div class="work-container">
      <div class="work-text">
        <h2>Robots and Medical Mechatronics Lab</h2>
        <p class="work-dates"><em>July 2020 - October 2022</em></p>
        <p class="work-position">Undergraduate Research Assistant</p>
      </div>
      <div class="work-skills">
              <span class="skill">SLAM</span>
              <span class="skill">PID</span>
              <span class="skill">Extended Kalman Filter</span>
              <span class="skill">SolidWorks</span>
              <span class="skill">Embedded systems</span>
              <span class="skill">System integration</span>
              <span class="skill">Python</span>
              <span class="skill">3D printing</span>
              <span class="skill">Fast-prototyping</span>
      </div>
      <div class="work-content">
        <h3><strong>Topic: System Integration for Autonomous Track Vehicle in Greenhouses</strong></h3>
        <ul class="contents">
          <li>Developed the control and tele-op systems on the vehicle using Nvidia Tx2 and TI F28388D.</li>
          <li>Developed an EKF-based localization framework fusing IMU, encoder, and LiDAR odometry data, achieving 0.1 m navigation accuracy and eliminated corridor trap incidents in greenhouse environments.</li>
          <li>Designed control system on a MCU with Ethernet communication to an embedded system for autonomous vehicle.</li>
          <li>Designed and fabricated a motor mount with a dual-bearing support system for a 1.5 m robotic arm, ensuring year-long operation in high-humidity, high-temperature greenhouse environments.</li>
          <li>Enhanced reliable path retracing via SLAM and online slip-ratio estimation for variable terrain conditions.</li>
        </ul>
      </div>
    </div>
  </div>
</section>

<!-- SECTION : education -->
<section id="education" class="education-section">
    <h2>Education</h2>

    <div class="education-grid-section">
        <div class="edu-container">
            <div class="edu-text">
                <h2>University of Michigan - Ann Arbor</h2>
                <p class="edu-dates">Aug. 2024 - May. 2026</p>
                <p class="edu-degree">Master of Science in Electrical and Computer Engineering, Robotics</p>
            </div>
            <div class="edu-logo">
                <img src="./assets/images/profile-image/Block_M-Hex.png" alt="University of Michigan logo">
            </div>
        </div>
        <div class="edu-container">
            <div class="edu-text">
                <h2>National Taiwan University</h2>
                <p class="edu-dates">Sep. 2019 - May. 2023</p>
                <p class="edu-degree">Bachelor of Science in Biomechatronics Engineering</p>
            </div>
            <div class="edu-logo">
                <img src="./assets/images/profile-image/NTU.png" alt="National Taiwan University logo">
            </div>
        </div>
    </div>
        
</section>

<!-- SECTION 3: project -->
<section id="projects" class="project-grid-section">
    <h2>Projects</h2>

    <div class="grid-container">
        
    <a href="./projects/ArmLab/index.html" class="project-link">
        <div class="project-card">
            <img src="./assets/images/project-image/ArmLab/ArmLab.png" alt="ArmLab image">
            <h3 class="project-title">Robotic Systems Lab - ArmLab</h3>
            <div class="project-skills">
                    <span class="skill">OpenCV</span>
                    <span class="skill">ROS2</span>
                    <span class="skill">Python</span>
                    <span class="skill">SolidWorks</span>
                    <span class="skill">System integration</span>
                    <span class="skill">Forward/Inverse kinematics</span>
                    <span class="skill">Fast prototyping</span>
                    <span class="skill">Motion control</span>
                    <span class="skill">Trajectory planning</span>
            </div>
            <p class="project-description">Developed a vision-guided control system for the Interbotix ReactorX-200 robotic arm using an RGB-D camera. The system features automated camera calibration, real-time object detection (size, color, pose), and precise motion control via forward and inverse kinematics. Implemented waypoint-based path planning for efficient object manipulation. Validated through performance in three robotics competitions.</p>
            <button class="read-more">Read more →</button>
        </div>
    </a>

    <a href="./projects/BotLab/index.html" class="project-link">
        <div class="project-card">
            <img src="./assets/images/project-image/BotLab/BotLab.png" alt="BotLab image">
            <h3 class="project-title">Robotic Systems Lab - BotLab</h3>
            <div class="project-skills">
                    <span class="skill">PID</span>
                    <span class="skill">A* path planning</span>
                    <span class="skill">Motion control</span>
                    <span class="skill">SLAM</span>
                    <span class="skill">Sensor fusion</span>
                    <span class="skill">Particle filter</span>
                    <span class="skill">C/C++</span>
                    <span class="skill">Python</span>
                    <span class="skill">Raspberry PI</span>
                    <span class="skill">YOLO</span>
                    <span class="skill">Multithread</span>
            </div>
            <p class="project-description">This project involved developing a fully autonomous differential-drive robot capable of navigating and mapping unknown environments. We implemented a control and navigation stack featuring PID control, gyrodometry-based odometry, and Pure Pursuit for smooth motion execution. For localization and mapping, we utilized a particle filter-based SLAM system operating in real time with approximately 6000 particles, achieving a localization RMS error of 3.25 cm. A* path planning and frontier exploration enabled the robot to autonomously explore and construct maps, successfully completing two industry-inspired challenges.</p>
            <button class="read-more">Read more →</button>
        </div>
    </a>

	<a href="./projects/ComputerVision/index.html" class="project-link">
        <div class="project-card">
            <img src="./assets/images/project-image/ComputerVision/ComputerVision.png" alt="Computer Vision">
            <h3 class="project-title">Computer Vision</h3>
            <div class="project-skills">
                    <span class="skill">Image filtering</span>
                    <span class="skill">Metric learning model</span>
                    <span class="skill">Diffusion models</span>
                    <span class="skill">OpenCV</span>
                    <span class="skill">Scipy</span>
                    <span class="skill">SIFT keypoint extraction</span>
                    <span class="skill">Panorama</span>
					          <span class="skill">Gaussian/Laplacian pyramids</span>
                    <span class="skill">PyTorch</span>
            </div>
            <p class="project-description">This coursework covers core concepts and practical implementations in computer vision. Each task involved hands-on development of classical and deep learning techniques for image analysis, recognition, and generation. The projects demonstrate proficiency in image filtering, frequency analysis, homography estimation, panoramic stitching, neural network training, and modern generative models such as diffusion networks.</p>
            <button class="read-more">Read more →</button>
        </div>
    </a>

    <a href="./projects/GraduateResearcher/index.html" class="project-link">
        <div class="project-card">
            <img src="./assets/images/project-image/GraduateResearcher/VGGT_W_GICP/room0.png" alt="Research Project">
            <h3 class="project-title">Research Project</h3>
            <div class="project-skills">
                    <span class="skill">Python</span>
                    <span class="skill">PyTorch</span>
                    <span class="skill">Gaussian splat</span>
                    <span class="skill">3D reconstruction</span>
                    <span class="skill">Semantic</span>
                    <span class="skill">VGGT</span>
                    <span class="skill">G-ICP</span>
                    <span class="skill">DINOv2</span>
                    <span class="skill">Replica Dataset</span>
                    <span class="skill">Scannet Dataset</span>
                    <span class="skill">Scannetpp Dataset</span>
            </div>
            <p class="project-description">This is the result of my graduate research project. Utilizing advanced techniques such as Gaussian splatting, 3D reconstruction, and semantic segmentation, I have developed models that achieve state-of-the-art performance in estimating camera poses, and 3D scene reconstruction.</p>
            <button class="read-more">Read more →</button>
        </div>
    </a>

    <a href="./projects/IM2GPS/index.html" class="project-link">
        <div class="project-card">
            <img src="./assets/images/project-image/IM2GPS/AllPointsWImage.png" alt="Research Project">
            <h3 class="project-title">IM2GPS Re-revisit: CLIP-powered Image Geolocation</h3>
            <div class="project-skills">
                    <span class="skill">Python</span>
                    <span class="skill">PyTorch</span>
                    <span class="skill">CLIP</span>
                    <span class="skill">ResNet</span>
                    <span class="skill">kNN Retrieval</span>
                    <span class="skill">t-SNE Visualization</span>
            </div>
            <p class="project-description">This project explores the feasibility of predicting the geographic origin of an image using modern multimodal models, inspired by the seminal works IM2GPS: Estimating Geographic Information from a Single Image and Revisiting IM2GPS in the Deep Learning Era. While the original IM2GPS pipeline relied primarily on handcrafted features and nearest-neighbor retrieval, and its successor incorporated deep CNN representations, this project investigates whether CLIP—a model trained on large-scale image-text pairs—can serve as a powerful visual feature extractor for the geolocation task.</p>
            <button class="read-more">Read more →</button>
        </div>
    </a>

    <a href="./projects/SensorFusion/index.html" class="project-link">
        <div class="project-card">
            <img src="./assets/images/project-image/SensorFusion/early_late_fusion_img.png" alt="Research Project">
            <h3 class="project-title">Early vs. Late Camera-LiDAR Fusion in 3D Object Detection and Tracking</h3>
            <div class="project-skills">
                    <span class="skill">Python</span>
                    <span class="skill">Sensor Fusion</span>
                    <span class="skill">SAM3</span>
                    <span class="skill">OpenPCDet</span>
                    <span class="skill">PV-RCNN</span>
                    <span class="skill">3D Object Detection</span>
                    <span class="skill">3D Object Tracking</span>
                    <span class="skill">KITTI Dataset</span>
            </div>
            <p class="project-description">This project compares two fusion strategies for 3D object detection and tracking on KITTI: early fusion (using camera segmentation to gate LiDAR points early) and late fusion (merging high-level outputs from SAM3 and PV-RCNN). The study highlights practical failure modes and why late fusion can be more robust in the presence of camera degradation and LiDAR-only category gaps.</p>
            <button class="read-more">Read more →</button>
        </div>
    </a>
    </div>
 </section>

<section id="skills" class="skills-section">
    <h2>Skills</h2>
        
    <ul class="skill-categories">
          <li>
            <div class="skills-card">
              <span class="category-label">Robotics & Control Systems</span>
              <ul class="skills-list">
                  <li class="skill">SLAM</li>
                  <li class="skill">EKF</li>
                  <li class="skill">PID</li>
                  <li class="skill">Motion Control</li>
                  <li class="skill">Pure Pursuit</li>
                  <li class="skill">A* path planning</li>
                  <li class="skill">Sensor fusion</li>
                  <li class="skill">Particle filter</li>
                  <li class="skill">Forward/Inverse kinematics</li>
                  <li class="skill">System integration</li>
                </ul>
            </div> 
          </li> 
        
          <li>
            <div class="skills-card">
              <span class="category-label">Programming Languages</span>
              <ul class="skills-list">
                  <li class="skill">Python</li>
                  <li class="skill">C/C++</li>
                  <li class="skill">MATLAB</li>
                  <li class="skill">SQLite</li>
                  <li class="skill">Java</li>
                </ul>
            </div> 
          </li> 

          <li>
            <div class="skills-card">
              <span class="category-label">Computer Vision</span>
              <ul class="skills-list">
                  <li class="skill">OpenCV</li>
                  <li class="skill">SIFT</li>
                  <li class="skill">YOLO</li>
                  <li class="skill">Image filtering</li>
                  <li class="skill">Object detection</li>
                  <li class="skill">Keypoint matching</li>
                  <li class="skill">Diffusion models</li>
                  <li class="skill">Metric learning</li>
                  <li class="skill">Panorama</li>
                  <li class="skill">Homography</li>
                </ul>
            </div> 
          </li> 

          <li>
            <div class="skills-card">
              <span class="category-label">Software & Development Tools</span>
              <ul class="skills-list">
                  <li class="skill">ROS2</li>
                  <li class="skill">Solidworks</li>
                  <li class="skill">Git</li>
                  <li class="skill">Multithread</li>
                  <li class="skill">Docker</li>
                  <li class="skill">Android Studio</li>
                  <li class="skill">3D printing</li>
                </ul>
            </div> 
          </li> 

          <li>
            <div class="skills-card">
              <span class="category-label">Hardware & Platforms</span>
              <ul class="skills-list">
                  <li class="skill">Nvidia Jetson TX2</li>
                  <li class="skill">TI F282388D</li>
                  <li class="skill">Raspberry Pi</li>
                  <li class="skill">IMU</li>
                  <li class="skill">RGB-D Camera</li>
                  <li class="skill">LiDAR</li>
                  <li class="skill">Robotic Arm</li>
                </ul>
            </div> 
          </li> 
        
      </ul>

</section>
<!-- SECTION 4: Contact-->
<!-- <section id="contact" class="contact-section">
    <h2>Contact</h2>

    <div class="group">
      
        <form action="https://formspree.io/f/https://formspree.io/f/manqyjzk" method="POST">
            <label for="name">Name</label>
            <input type="text" id="name">

            <label for="email">Email</label>
            <input type="email" id="email" name="email">

            <label for="message">Message</label>
            <textarea id="message" cols="30" rows="10" name="message"></textarea>

            <button type="submit">Send Message</button>
        </form>
    </div>
  </section>
</div> -->

    <!-- Google Tag Manager (noscript) -->
    <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-WL3LR5QV"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
    <!-- End Google Tag Manager (noscript) -->

     


    <footer>
    <div class="footer-content">
        <div class="links">
            <a href="/">
                <span>Home</span>
            </a>
            <a href="/projects/">
                <span>Projects</span>
            </a>
            <a href="https://drive.google.com/file/d/13Z3duVzh-gguPU5r03oJVEE6rV9rd3DS/view?usp=sharing" target="_blank" rel="noopener noreferrer">
                <span>Resume</span>
            </a>
        </div>
    </div>
    <div class="license">
        <!-- <span>For any question or suggestion for the portfolio template or projects, reach out <a class="help" href="mailto:aram.lee12@gmail.com"> Here</a> </span> -->
        <p>FreeToEngineer portfolio template © 2025 by Aram Lee is licensed under <a href="https://creativecommons.org/licenses/by/4.0/?ref=chooser-v1">CC BY 4.0</a></p>
    </div>
</footer>


</body></html>